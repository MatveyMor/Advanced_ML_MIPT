{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Matvey Morozov 676.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework01: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02 seminar](https://github.com/ml-mipt/ml-mipt/blob/advanced/week02_CNN_n_Vanishing_gradient/week02_CNN_for_texts.ipynb). Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P8zS7m-gycN5",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nvpQk7vxm1lS"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N14ITJYpm1lW",
        "colab": {}
      },
      "source": [
        "# uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "#!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
        "#!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mcxVsi7tz_l",
        "outputId": "c759adc4-a2d2-4774-fe9b-f9ae62275a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ml-mipt/ml-mipt/advanced/homeworks/homework1_three_headed_network/network.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-06 15:55:02--  https://raw.githubusercontent.com/ml-mipt/ml-mipt/advanced/homeworks/homework1_three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py.6’\n",
            "\n",
            "\rnetwork.py.6          0%[                    ]       0  --.-KB/s               \rnetwork.py.6        100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-06 15:55:02 (254 MB/s) - ‘network.py.6’ saved [1469/1469]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bV982Sg3whDH",
        "outputId": "089a9cd8-9680-4e75-adc2-3ce85d090d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12612628</td>\n",
              "      <td>Engineering Systems Analyst</td>\n",
              "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
              "      <td>Dorking, Surrey, Surrey</td>\n",
              "      <td>Dorking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 30000/annum 20-30K</td>\n",
              "      <td>25000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12612830</td>\n",
              "      <td>Stress Engineer Glasgow</td>\n",
              "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
              "      <td>Glasgow, Scotland, Scotland</td>\n",
              "      <td>Glasgow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 - 35000/annum 25-35K</td>\n",
              "      <td>30000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12612844</td>\n",
              "      <td>Modelling and simulation analyst</td>\n",
              "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
              "      <td>Hampshire, South East, South East</td>\n",
              "      <td>Hampshire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 40000/annum 20-40K</td>\n",
              "      <td>30000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12613049</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
              "      <td>27500</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12613647</td>\n",
              "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
              "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 30000/annum 20-30K</td>\n",
              "      <td>25000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Id  ...        SourceName\n",
              "0  12612628  ...  cv-library.co.uk\n",
              "1  12612830  ...  cv-library.co.uk\n",
              "2  12612844  ...  cv-library.co.uk\n",
              "3  12613049  ...  cv-library.co.uk\n",
              "4  12613647  ...  cv-library.co.uk\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UuuKIKfrycOH",
        "colab": {}
      },
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RUWkpd7PycOQ",
        "outputId": "3b4ba475-f1b2-413d-c854-7bb8ff0ea5de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "356it [00:00, 3552.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "239768it [01:00, 3940.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "944Hj1Psm1mN",
        "outputId": "ba1e216e-943f-4b63-d388-49042bc31f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "token_counts.most_common(1)[0][1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GiOWbc15ycOb",
        "outputId": "b3518324-600a-480d-c7cb-d58bbe250ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JEsLeBjVycOw",
        "colab": {}
      },
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JiBlPkdKycOy",
        "outputId": "9e0937f1-f663-481b-956b-b44047dee790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DpOlBp7ZycO6",
        "outputId": "6d2c3d37-f1ab-4318-f6b7-0b8fb519766b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
              "               sparse=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TngLcWA0ycO_",
        "outputId": "d2411a9a-fe5f-4126-a51c-7e0a36f8c95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2PXuKgOSycPB",
        "colab": {}
      },
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I6LpEQf0ycPD",
        "colab": {}
      },
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "El1yv7Fmm1no"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gjkBC5kPm1ns",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9yFLnyfGm1n3",
        "colab": {}
      },
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "74kHLL65m1oB"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wardN2Otm1oF",
        "colab": {}
      },
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L3k7ZF7Tm1oQ",
        "colab": {}
      },
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GblZZCjym1oa",
        "colab": {}
      },
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R6NJqXA6m1ol",
        "outputId": "83fe87a0-8cf0-4fb4-af12-f9bddfc8bbe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SnoJBR30m1o6"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mHSrW0ium1o_",
        "outputId": "e4dedac7-ccb6-47e9-f85b-2d7d6416420c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0684],\n",
              "        [-0.2749],\n",
              "        [-0.1634]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T-h7anFXm1pS",
        "outputId": "1fb225b2-c8fd-4c1b-f52a-828fe84cc204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch[\"Categorical\"].shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3746)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZYKRRokjm1pe"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N2BucNKCm1pk",
        "outputId": "07b3e6a0-cf77-4236-bbc6-3370cb38bb02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = simple_model\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        target = torch.tensor(target)\n",
        "\n",
        "\n",
        "        predictions = model(batch)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        # <YOUR CODE HERE>\n",
        "\n",
        "        history.append(loss.data.numpy())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        if idx > 190: break"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nknAXQggv9P9UV+n6YduOnAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YADsf9B0hd6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "082b29a5-73c9-44cd-85ac-7b9f76cec2ad"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXBarGL4m1pw"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wTgzvp_EuaW0",
        "colab": {}
      },
      "source": [
        "import network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IehyM7Glm1qF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1c4485c-8b03-4b68-c784-a7a510b6861d"
      },
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lwdYKi1hgqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e4d9cdf-5835-44fd-cd64-ac2376d79a3c"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4DaKNuvwm1qQ",
        "colab": {}
      },
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        "    hid_size=64\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SS43RZP4m1qe",
        "colab": {}
      },
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jp28UO8cm1q6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "444353b6-4989-4eb7-84db-5a0997165905"
      },
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seems fine!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjQryNfWfW21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VbWWkcKZm1rD"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aOqDtOrIm1rJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e150bfad-3ef3-4fb4-be01-ceb2f731d8b9"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "# Training pipeline comes here (almost the same as for the simple_model)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train, 256)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch = [\n",
        "              torch.tensor(batch['Title'], dtype=torch.long).to(device),\n",
        "              torch.tensor(batch['FullDescription'], dtype=torch.long).to(device),\n",
        "              torch.tensor(batch['Categorical']).to(device)\n",
        "        ]\n",
        "\n",
        "        target = torch.tensor(target)\n",
        "        target = target.to(device)\n",
        "\n",
        "        predictions = model(batch)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        # <YOUR CODE HERE>\n",
        "\n",
        "        history.append(loss.data.cpu().numpy())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRpB/x/aKMMC01GVlwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z9ZwbQ4qm1rV"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1J4DkpzVm1rc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "000b47c5-70d6-4494-885e-3ada2f447974"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_emb): Embedding(33795, 64)\n",
              "  (title_conv1_1): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
              "  (title_pool_overtime): AdaptiveMaxPool1d(output_size=1)\n",
              "  (full_emb): Embedding(33795, 64)\n",
              "  (full_conv1_1): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
              "  (full_conv1_2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(1,))\n",
              "  (full_conv1_3): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(2,))\n",
              "  (full_pool_overtime1): AdaptiveMaxPool1d(output_size=1)\n",
              "  (category_out): Linear(in_features=3746, out_features=128, bias=True)\n",
              "  (last_fc): Linear(in_features=448, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uRPBwZhGm1rm",
        "colab": {}
      },
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqVbl9olppmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-j6iMDWGm1r3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "49b61d6b-4613-4573-cf3f-0587a785fb0b"
      },
      "source": [
        "generate_submission(model, data_for_autotest, batch_size=256, name='Submission')\n",
        "print('Submission file generated')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20it [00:15,  1.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.23036\n",
            "Mean absolute error: 0.37480\n",
            "Submission file generated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z7YbLJO_m1sA"
      },
      "source": [
        "__To hand in this homework, please upload `network.py` file with code and `submission.csv` to the google form.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSwYidfi6iM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}